#!/usr/bin/env python3
import os
import re
import requests
from datetime import datetime

# Base suppos√©e pour les PDF (ajust√©e selon leur structure CDN)
CDN_BASE = "https://www.ohm-energie.com/content/dam/ohm-public/pdf/"
# Dossier o√π tu veux stocker et surveiller
LOCAL_DIR = "/mnt/c/Users/johan/OneDrive/Documents/ELECTRICITE PARTICULIER/OHM ENERGIE"
# Fichier de suivi
STATE_FILE = os.path.join(LOCAL_DIR, "ohm_watchdog_state.txt")

def fetch_listing():
    """Essaie d'obtenir la liste des fichiers PDF du CDN Ohm."""
    try:
        resp = requests.get(CDN_BASE, timeout=10)
        resp.raise_for_status()
    except Exception as e:
        print(f"‚ö†Ô∏è Impossible d'acc√©der √† {CDN_BASE}: {e}")
        return []

    urls = re.findall(r'href="([^"]+\.pdf)"', resp.text)
    full_urls = [u if u.startswith("http") else CDN_BASE + u for u in urls]
    full_urls = [u for u in full_urls if "ohm" in u.lower()]
    return sorted(set(full_urls))

def load_previous_state():
    if not os.path.exists(STATE_FILE):
        return set()
    with open(STATE_FILE, "r") as f:
        return set(line.strip() for line in f if line.strip())

def save_state(urls):
    with open(STATE_FILE, "w") as f:
        for u in sorted(urls):
            f.write(u + "\n")

def check_new_files():
    print(f"üîç V√©rification des grilles Ohm : {CDN_BASE}")
    old_urls = load_previous_state()
    new_urls = fetch_listing()
    if not new_urls:
        print("‚ö†Ô∏è Aucun fichier d√©tect√© (CDN vide ou bloqu√©).")
        return

    new_links = [u for u in new_urls if u not in old_urls]

    if not new_links:
        print("‚úÖ Aucune nouvelle grille d√©tect√©e.")
    else:
        print("üö® Nouvelles grilles d√©tect√©es :")
        for u in new_links:
            print(f" ‚ûï {u}")

        # Sauvegarde de l‚Äô√©tat mis √† jour
        save_state(set(new_urls))
        print("üì¶ √âtat mis √† jour.")

if __name__ == "__main__":
    check_new_files()
